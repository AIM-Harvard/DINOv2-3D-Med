# DINOv2 3D Training Configuration
# Uses processed patches, optimized for low memory usage

vars:
    run_name: "DINOv2_pretrain_primus"
    img_size: [160, 160, 160]
    hidden_size: 864
    patch_size: [8, 8, 8]
    max_epochs: 25
    batch_size: 2

trainer:
    _target_: pytorch_lightning.Trainer
    benchmark: true
    max_epochs: "%vars::max_epochs"
    accelerator: gpu
    strategy: ddp_find_unused_parameters_true
    enable_model_summary: false
    log_every_n_steps: 10
    limit_train_batches: 250
    fast_dev_run: false
    num_sanity_val_steps: 0
    precision: 16-mixed
    devices: 4
    detect_anomaly: false
    sync_batchnorm: true
    accumulate_grad_batches: 2
    logger:
        _target_: pytorch_lightning.loggers.WandbLogger
        project: "dinov2"
        name: "%vars::run_name"
        save_dir: "$'/mnt/data1/suraj/dinov2_experiments/dinov2_pretrain/' + @vars::run_name"
    callbacks:
        - _target_: pytorch_lightning.callbacks.ModelCheckpoint
          dirpath: "$'/mnt/data1/suraj/dinov2_experiments/dinov2_pretrain/' + @vars::run_name"
          filename: "dinov2_3d_fixed_{epoch:03d}"
          save_last: true
          every_n_epochs: 1
          save_on_train_epoch_end: true

model:
    _target_: project.training.DINOv2_3D_LightningModule
    batch_size_per_device: "%vars::batch_size"
    hidden_size: "%vars::hidden_size"
    ibot_separate_head: true
    base_lr: 0.0001
    layer_decay: 0.9
    gradient_clip_val: 3.0
    teacher_temp_warmup_epochs: "$max(1, int(@vars::max_epochs * 0.03))"
    teacher_temp_min: 0.01
    teacher_temp_max: 0.03
    freeze_last_layer_epochs: 1
    projection_dim: 65536
    weight_decay: 0.04
    backbone:

data:
    _target_: project.training.DataModule
    num_workers: 6
    batch_size: "%vars::batch_size"
    pin_memory: true
    drop_last: true
    train_dataset:
        _target_: project.utils.safe_dataset.SafeDataset
        dataset:
            _target_: monai.data.Dataset
            data:
            transform:
                _target_: torchvision.transforms.Compose
                transforms:
                    - _target_: monai.transforms.LoadImaged
                      keys: ["image"]
                      image_only: true
                    - _target_: monai.transforms.EnsureChannelFirstd
                      keys: ["image"]
                    - _target_: monai.transforms.Orientationd
                      keys: ["image"]
                      axcodes: SPL
                    - _target_: monai.transforms.Spacingd
                      keys: ["image"]
                      pixdim: [1.0, 1.0, 1.0]
                      mode: bilinear
                    - _target_: monai.transforms.CropForegroundd
                      keys: ["image"]
                      source_key: "image"
                    - _target_: monai.transforms.SpatialPadd
                      keys: ["image"]
                      spatial_size: "%vars::img_size"
                      value: -1024
                    - _target_: monai.transforms.ScaleIntensityRanged
                      keys: ["image"]
                      a_min: -1024
                      a_max: 2048
                      b_min: 0
                      b_max: 1
                      clip: true
                    - _target_: monai.transforms.RandSpatialCropd
                      keys: ["image"]
                      roi_size: "%vars::img_size"
                    - _target_: torchvision.transforms.Lambda
                      lambd: "$lambda x: x['image'].as_tensor()"
                    - _target_: project.transforms.dinov2_aug.DINOv2Augmentation3D
                      global_view_scale: [0.3, 1.0]
                      global_view_size: "$@vars::img_size[0]"
                      local_view_scale: [0.3, 1.0]
                      local_view_size: "$@vars::img_size[0]//2"
                      num_local_views: 2
                    - _target_: torchvision.transforms.Lambda
                      lambd: "$lambda x: (x, False)"
